1.-
    a) Compila y ejecuta el programa DeviceInfo.c. Comprueba la información 
    que te muestra. No te preocupes si no entiendes todav´ıa alguno de los 
    datos mostrados.

        Adjunto info.txtx

    b) Revisa el código y averigua qué funciones se utilizan para obtener 
    la lista de plataformas y la lista de dispositivos de cada una de ellas. 
    Consulta en la guía de referencia o en la página 
    https://www.khronos.org/opencl/ el significado de los argumentos de ambas 
    funciones ¿Por qué se llama dos veces a ambas funciones?

        Obtener el numero de plataformas:
        clGetPlatformIDs(num_platforms, platform, NULL);

        Obtener el nombre de cada plataforma:
        clGetPlatformInfo(platform[i], CL_PLATFORM_NAME, sizeof(string), &string, NULL);
        
        Obtener el numero de dispositivos:
        clGetDeviceIDs(platform[i], CL_DEVICE_TYPE_ALL, 0, NULL, &num_devices) 

        Obtener los IDs de dispositivos:
        clGetDeviceIDs(platform[i], CL_DEVICE_TYPE_ALL, num_devices, device, NULL);

    c) ¿Qué funciones se utilizan para obtener información de las 
    plataformas? ¿y de los dispositivos? Averigua el significado de los 
    argumentos de ambas funciones

        clGetPlatformInfo y clGetDeviceInfo

        Parámetros en:
        https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/clGetDeviceInfo.html ,
        https://www.khronos.org/registry/OpenCL/sdk/1.0/docs/man/xhtml/clGetPlatformInfo.html

    d) Modifica el programa para que por cada dispositivo se muestre también 
    su máxima frecuencia de reloj.

        // Get device frequency
        cl_uint freq;
        err = clGetDeviceInfo(device[j], CL_DEVICE_MAX_CLOCK_FREQUENCY, sizeof(cl_uint), &freq, NULL);
        checkError(err, "Getting device name");
        printf("\t\tFreq: %d\n", string);




-------------------------------------------------------------------------------------

2.- 
    a) Revisa el código del programa vadd.c y localiza las principales 
    etapas del mismo y las llamadas a la API que se realizan en cada una 
    de ellas.

        Las llamadas están indicadas sobre el código con comentarios.    

    b) ¿Cómo elegimos el tipo de dispositivo sobre el que vamos a 
    ejecutar el código?

        #define DEVICE_TYPE CL_DEVICE_TYPE_ALL

        err = clGetDeviceIDs(platform, DEVICE_TYPE, 1, &device, NULL);
        checkError(err, "Finding a device");
    
    c) ¿Cómo procesamos los posibles errores de las llamadas a la API?

        con el método checkError

    d) ¿Cómo medimos el tiempo empleado por el kernel y nos aseguramos 
    de que este haya acabado?

        Con una función auxiliar llamada wtime() y esperando a que acabe 
        con la llamada clFinish(commands) a la API

    e) ¿Dónde está el código del kernel a ejecutar y cómo construimos 
    el programa a partir de él?

        En el archivo vadd.cl. Se construye el programa mediante las llamadas:

        char * filename="vadd.cl";

        char *kernelSource = getKernelSource(filename);
        program = clCreateProgramWithSource(context, 1, (const char **) &kernelSource, NULL, &err);

        De esta manera se pasa al programa el código del kernel como una cadena.


-------------------------------------------------------------------------------------

3.-
    a) Modifica el código del kernel para que cada work-item sume uno de los 
    elementos de los tres vectores.

        Adjunto vadd_abc.cl



    b) Modifica el código del host para que el programa gestione la suma de tres 
    vectores generados aleatoriamente usando la nueva versión del kernel.

        Adjunto vadd_abc.c


-------------------------------------------------------------------------------------

4.-
    a) Revisa el código del programa matmul.c y averigua qué hacen las funciones 
    auxiliares parseArguments, getDeviceList y getDeviceName

        parseArguments asigna a deviceIndex el valor de un argumento pasado 
        al llamar al programa (--device X)

        getDeviceList devuelve el numero de dispositivos

        getDeviceName devuelve el nombre del dispositivo 

    b) Revisa el código de creación de los buffers. ¿Cómo se transfieren las 
    matrices de entrada al dispositivo? Modifica el código para que las matrices 
    A y B se transfieran de otra forma

        Las matrices de entrada al dispositivo se transfieren mediante la instrucción:
        clCreateBuffer

    c) Prueba el código y observa el resultado obtenido para distintos tamaños de 
    matrices. ¿Cómo evolucionan las prestaciones con el tamaño de las matrices?

        Ejecuciones entre tamaños 10 y 1000:

        ===== Sequential, matrix mult (dot prod), order 10 on host CPU ======
        0.00 seconds at 1000.0 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 10 ======
        0.00 seconds at 18.2 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 50 on host CPU ======
        0.00 seconds at 2155.2 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 50 ======
        0.00 seconds at 1543.2 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 100 on host CPU ======
        0.00 seconds at 3937.0 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 100 ======
        0.00 seconds at 8771.9 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 500 on host CPU ======
        0.11 seconds at 2319.7 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 500 ======
        0.00 seconds at 94768.8 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 1000 on host CPU ======
        1.14 seconds at 1751.0 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 1000 ======
        0.09 seconds at 22833.9 MFLOPS 



    d) ¿Qué tamaño global de dominio se utiliza para lanzar el kernel? ¿Qué 
    tamaño  de workgroup? Modifica el código para que se use un tamaño de 
    work-group introducido en la línea de órdenes

        Al utilizar null es un tamaño elgido por OpenCL.

        int BUFFER;
        BUFFER = atoi(argv[2]);
        const size_t local[2] = {BUFFER, BUFFER};
        err = clEnqueueNDRangeKernel(
            commands,
            kernel,
            2, NULL,
            global, local,
            0, NULL, NULL);
        checkError(err, "Enqueueing kernel");


    e) Comprueba el efecto sobre las prestaciones de mantener un tamaño de 
    matriz e ir variando el tamaño de work-group. ¿Obtienes en algún caso mejores 
    prestaciones que cuando no especificabas el tamaño del work-group?

        global: 128,256,512,1024,2048
        local: 4x4

        ===== Sequential, matrix mult (dot prod), order 128 on host CPU ======
        0.00 seconds at 1691.3 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 128 ======
        0.00 seconds at 12192.7 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 256 on host CPU ======
        0.03 seconds at 977.4 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 256 ======
        0.00 seconds at 46028.0 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 512 on host CPU ======
        0.31 seconds at 873.9 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 512 ======
        0.00 seconds at 65809.1 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======
        2.22 seconds at 969.0 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======
        0.05 seconds at 41072.7 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 2048 on host CPU ======
        16.40 seconds at 1047.2 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 2048 ======
        0.23 seconds at 75988.2 MFLOPS

        global: 1024
        local: 1x, 2x, 4x, 8x

        ===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======
        2.27 seconds at 947.8 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======
        0.20 seconds at 10583.7 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======
        2.24 seconds at 959.8 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======
        0.05 seconds at 40840.7 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======
        2.31 seconds at 927.9 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======
        0.05 seconds at 40036.6 MFLOPS 

        Using OpenCL device:       Intel(R) Xeon(R) CPU E5-2697 v2 @ 2.70GHz

        ===== Sequential, matrix mult (dot prod), order 1024 on host CPU ======
        2.27 seconds at 944.0 MFLOPS 

        ===== OpenCL, matrix mult, C(i,j) per work item, order 1024 ======
        0.05 seconds at 41223.2 MFLOPS 

    f) ¿Puedes usar cualquier tamaño de work-group? ¿Por qué?

        TODO



-------------------------------------------------------------------------------------

5.-
    a) Escribe el kernel row.cl en el que cada work-item calcula una fila de la 
    matriz resultado C. Las matrices se guardarán en memoria global.



    b) Modificar el código del programa matmul.c para que, después de realizar las 
    dos primeras versiones del producto utilice el nuevo kernel para calcular el 
    producto.



    c) Compara las prestaciones de las tres versiones modificando el tamaño de las 
    matrices y del work-group.




